{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                0\n",
      "age               0\n",
      "domain1_var1    438\n",
      "domain1_var2    438\n",
      "domain2_var1     39\n",
      "domain2_var2     39\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10008</td>\n",
       "      <td>35.326582</td>\n",
       "      <td>15.769168</td>\n",
       "      <td>65.782269</td>\n",
       "      <td>44.643805</td>\n",
       "      <td>50.448485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0  10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1  10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2  10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "4  10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "5  10008  35.326582     15.769168     65.782269     44.643805     50.448485"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_scores.csv\")\n",
    "print(df.isna().sum())\n",
    "df = df.dropna()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                int64\n",
      "age             float64\n",
      "domain1_var1    float64\n",
      "domain1_var2    float64\n",
      "domain2_var1    float64\n",
      "domain2_var2    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5434.000000</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>5434.000000</td>\n",
       "      <td>5434.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15929.972396</td>\n",
       "      <td>49.615210</td>\n",
       "      <td>51.474438</td>\n",
       "      <td>59.246408</td>\n",
       "      <td>47.244966</td>\n",
       "      <td>51.916310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3414.559796</td>\n",
       "      <td>13.441014</td>\n",
       "      <td>10.192038</td>\n",
       "      <td>11.387837</td>\n",
       "      <td>11.082251</td>\n",
       "      <td>11.794651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>15.769168</td>\n",
       "      <td>1.021874</td>\n",
       "      <td>0.991172</td>\n",
       "      <td>0.815285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12975.750000</td>\n",
       "      <td>40.129361</td>\n",
       "      <td>44.780129</td>\n",
       "      <td>52.397196</td>\n",
       "      <td>40.072138</td>\n",
       "      <td>44.532715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15982.500000</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>51.848060</td>\n",
       "      <td>60.054213</td>\n",
       "      <td>47.760527</td>\n",
       "      <td>52.542651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18904.750000</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>58.498056</td>\n",
       "      <td>67.143291</td>\n",
       "      <td>55.003507</td>\n",
       "      <td>59.832945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21754.000000</td>\n",
       "      <td>84.491113</td>\n",
       "      <td>81.325580</td>\n",
       "      <td>94.702874</td>\n",
       "      <td>80.834495</td>\n",
       "      <td>94.509903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id          age  domain1_var1  domain1_var2  domain2_var1  \\\n",
       "count   5434.000000  5434.000000   5434.000000   5434.000000   5434.000000   \n",
       "mean   15929.972396    49.615210     51.474438     59.246408     47.244966   \n",
       "std     3414.559796    13.441014     10.192038     11.387837     11.082251   \n",
       "min    10001.000000    14.257265     15.769168      1.021874      0.991172   \n",
       "25%    12975.750000    40.129361     44.780129     52.397196     40.072138   \n",
       "50%    15982.500000    48.948756     51.848060     60.054213     47.760527   \n",
       "75%    18904.750000    59.580851     58.498056     67.143291     55.003507   \n",
       "max    21754.000000    84.491113     81.325580     94.702874     80.834495   \n",
       "\n",
       "       domain2_var2  \n",
       "count   5434.000000  \n",
       "mean      51.916310  \n",
       "std       11.794651  \n",
       "min        0.815285  \n",
       "25%       44.532715  \n",
       "50%       52.542651  \n",
       "75%       59.832945  \n",
       "max       94.509903  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5434, 5)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"fMRI_train_pk\"\n",
    "\n",
    "file_ls = []\n",
    "y_ls = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_ls.append(os.path.join(DATA_PATH, str(int(row[\"Id\"]))+\".pk\"))\n",
    "    ys = [item for _, item in row.iteritems()]\n",
    "    y_ls.append(ys[1:])\n",
    "    \n",
    "y_ls = np.array(y_ls, dtype = np.float32)\n",
    "print(y_ls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_f, test_f, train_label, test_label = train_test_split(\n",
    "    file_ls, y_ls, test_size = 0.3, random_state = 42\n",
    ")\n",
    "\n",
    "val_f, evl_f, val_label, evl_label = train_test_split(\n",
    "    test_f, test_label, test_size = 0.5, random_state = 42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_label.shape)\n",
    "print(val_label.shape)\n",
    "print(evl_label.shape)\n",
    "\n",
    "print(train_label.min(axis = 0))\n",
    "print(val_label.min(axis = 0))\n",
    "print(evl_label.min(axis = 0))\n",
    "\n",
    "print(train_label.max(axis = 0))\n",
    "print(val_label.max(axis = 0))\n",
    "print(evl_label.max(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 100, 50)\n",
    "fig, ax = plt.subplots(3, 2)\n",
    "fig.set_size_inches(18.5, 15.5)\n",
    "for i in range(5):\n",
    "    \n",
    "    ax[i // 2, i % 2].hist(train_label[:,i], bins, alpha = 0.5, label = \"Train\")\n",
    "    ax[i // 2, i % 2].hist(val_label[:,i], bins, alpha = 0.5, label = \"Validation\")\n",
    "    ax[i // 2, i % 2].hist(evl_label[:,i], bins, alpha = 0.5, label = \"Evaluation\")\n",
    "    ax[i // 2, i % 2].legend([\"Train\", \"Validation\", \"Evaluation\"])\n",
    "    ax[i // 2, i % 2].set_title(df.columns[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = (img - mean) / std\n",
    "    img = img.transpose()\n",
    "    return img\n",
    "\n",
    "def DataGenerator(file_list, y_list):\n",
    "    def generator():\n",
    "        for file, y in zip(file_list, y_list):\n",
    "            #ith h5py.File(file, \"r\") as f:\n",
    "                #img = f[\"SM_feature\"][()]\n",
    "            with open(file, \"rb\") as f:\n",
    "                img = pickle.load(f)\n",
    "            img = normalize(img)\n",
    "            yield img, y\n",
    "\n",
    "    return generator\n",
    "            \n",
    "def DatasetReader(file_list, y_list, shuffle_size, batch_size):\n",
    "    generator = DataGenerator(file_list, y_list)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_types = (tf.float32, tf.float32),\n",
    "        output_shapes = (tf.TensorShape((53, 63, 52, 53)), tf.TensorShape((5,)))\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.repeat().batch(batch_size).shuffle(shuffle_size)\n",
    "    \n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "train_set = DatasetReader(train_f, train_label, 24, BATCH_SIZE)\n",
    "val_set = DatasetReader(val_f, val_label, 12, BATCH_SIZE)\n",
    "evl_set = DatasetReader(evl_f, evl_label, 12, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_set.take(2):\n",
    "    print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv3D = partial(keras.layers.Conv3D, kernel_size=3, strides=(1,)*3,\n",
    "        padding=\"SAME\", use_bias=True, kernel_regularizer = keras.regularizers.l2(0.01))\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    # separate construction and execution\n",
    "    # be aware of the strides' shape\n",
    "    def __init__(self, filters, strides=(1,)*3, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "                \n",
    "        # a list a layers that can be iterated\n",
    "        self.main_layers = [\n",
    "                DefaultConv3D(self.filters, strides=self.strides, kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv3D(self.filters, strides=(1,)*3, kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "                ]\n",
    "        self.skip_layers = []\n",
    "        if np.prod(self.strides) > 1:\n",
    "            #self.skip_layers = [keras.layers.MaxPool3D(pool_size=(2,)*3, strides=strides, padding=\"SAME\")]\n",
    "            \n",
    "            self.skip_layers = [\n",
    "                DefaultConv3D(self.filters, kernel_size=1, strides=self.strides, kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "                ]          \n",
    "            \n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        orig_x = inputs\n",
    "        \n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x) # f(x)\n",
    "        \n",
    "        for layer in self.skip_layers:\n",
    "            orig_x = layer(orig_x)\n",
    "        \n",
    "        return self.activation(x + orig_x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResidualUnit, self).get_config()\n",
    "        config.update({'filters': self.filters, 'strides':self.strides})\n",
    "        \n",
    "        return config\n",
    "\n",
    "filters = (16, 32, 64)\n",
    "strides = (1, 2, 2)\n",
    "#(1,1,1)\n",
    "model = keras.models.Sequential()\n",
    "model.add(DefaultConv3D(filters[0], kernel_size=3, strides=(1,)*3,\n",
    "        input_shape=[53, 63, 52, 53], kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool3D(pool_size=(2,)*3, padding=\"SAME\"))\n",
    "\n",
    "for filter, stride in zip(filters[1:], strides[1:]):\n",
    "    model.add(ResidualUnit(filter, strides=(stride,)*3))\n",
    "    model.add(ResidualUnit(filter, strides=(1,)*3))\n",
    "\n",
    "model.add(keras.layers.GlobalAvgPool3D())\n",
    "model.add(keras.layers.Flatten()) # 128 \n",
    "model.add(keras.layers.Dense(16, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.002)))\n",
    "#model.add(keras.layers.Dropout(0.5 ))\n",
    "model.add(keras.layers.Dense(5))\n",
    "#model.add(keras.layers.Dropout(0.2 ))\n",
    "optimizer = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"mse\", \"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./my_logs/First_try.h5\", \n",
    "        monitor = 'val_loss', mode = 'min',\n",
    "        save_best_only=True\n",
    "        )\n",
    "\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f} \\n\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"./my_logs/First_try\")\n",
    "\n",
    "def get_run_logdir(comment=None):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S{}\".format(comment))\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_set, steps_per_epoch= 1024 // BATCH_SIZE, epochs=500,\n",
    "          validation_data=val_set,\n",
    "          validation_steps=800 // BATCH_SIZE,\n",
    "          callbacks=[checkpoint_cb,  \n",
    "                     PrintValTrainRatioCallback(), tensorboard_cb]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
